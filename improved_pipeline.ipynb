{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from find_prices_nonoverlap import *\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import (GridSearchCV, StratifiedKFold, cross_val_score)\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Data: cleaning data\n",
      "Preparing Data: splitting test/train/validation\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('single_family_home_values.csv')\n",
    "\n",
    "print('Preparing Data: cleaning data')\n",
    "not_useful_fields = ['id','city','state']#, 'address']\n",
    "date_fields = ['lastSaleDate', 'priorSaleDate']\n",
    "required_fields = ['address','latitude','longitude','zipcode','bedrooms',\n",
    "                   'bathrooms','rooms','squareFootage',\n",
    "                   'lotSize','yearBuilt', 'lastSaleAmount' \n",
    "                   'lastSaleDate','estimated_value']\n",
    "zero_to_nan_fields = None\n",
    "nan_to_zero_fields = ['latitude','longitude','priorSaleDate','priorSaleAmount']\n",
    "# categorical_fields = ['zipcode']\n",
    "# remove_outliers=False\n",
    "# df2, new_fields = prepare_data(df, not_useful_fields=not_useful_fields,\n",
    "#         date_fields=date_fields,\n",
    "#         remove_outliers=remove_outliers,\n",
    "#         required_fields=required_fields,\n",
    "#         zero_to_nan_fields=zero_to_nan_fields,\n",
    "#         nan_to_zero_fields=nan_to_zero_fields,\n",
    "#         )\n",
    "#         categorical_fields=categorical_fields,\n",
    "print('Preparing Data: splitting test/train/validation')\n",
    "df_train, df_test, df_validation = train_validate_test_split(df)\n",
    "\n",
    "X_test = df_test[df_test.columns.drop('estimated_value')]\n",
    "y_test = df_test['estimated_value']\n",
    "\n",
    "X_train = df_train[df_train.columns.drop('estimated_value')]\n",
    "y_train = df_train['estimated_value'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tzip = ImputeZipCodes()\n",
    "#tzip.fit_transform(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up pipeline\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import (\n",
    "    ExtraTreesRegressor, GradientBoostingRegressor, AdaBoostRegressor \n",
    ")\n",
    "\n",
    "print(\"Setting up pipeline\")\n",
    "features = ('latitude', 'longitude', 'zipcode',\n",
    "            'bedrooms', 'bathrooms','rooms', \n",
    "            'squareFootage', 'lotSize', \n",
    "            'yearBuilt',\n",
    "            'lastSaleAmount','lastSaleDateYear','lastSaleDateMonth','lastSaleDateDayOfWeek')\n",
    "\n",
    "\n",
    "#: Note imputer will strip away column heads, it has to be after featurize\n",
    "#reg_function = LGBMRegressor()\n",
    "#reg_function = XGBRegressor()\n",
    "reg_function = RandomForestRegressor(n_jobs=3)\n",
    "#reg_function = GradientBoostingRegressor()\n",
    "#reg_function = ExtraTreesRegressor(n_estimators=2)\n",
    "#reg_function = AdaBoostRegressor(); #Really bad\n",
    "\n",
    "# prepare_data_pipeline = Pipeline([\n",
    "#             ('impute_zip_codes', ImputeZipCodes()),\n",
    "#           ('featurize', featurize(features)),\n",
    "#           ('imputer', Imputer(missing_values=np.nan, strategy=\"mean\", axis=0)),\n",
    "\n",
    "#             ])\n",
    "\n",
    "prepare_data_pipeline = Pipeline([\n",
    "            ('prepare_data', PrepareData(required_fields=required_fields,\n",
    "                                         date_fields=date_fields,\n",
    "                                        zero_to_nan_fields=zero_to_nan_fields,\n",
    "                                        nan_to_zero_fields=nan_to_zero_fields)), \n",
    "          ('featurize', featurize(features)),\n",
    "          ('imputer', Imputer(missing_values=np.nan, strategy=\"mean\", axis=0)),\n",
    "            ])\n",
    "\n",
    "fit_data_pipeline = Pipeline([\n",
    "          ('forest', reg_function)\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derringi/.edm/envs/may2018/lib/python2.7/site-packages/IPython/core/debugger.py:243: DeprecationWarning: The `color_scheme` argument is deprecated since version 5.1\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m/Users/derringi/Dropbox/projects/job_projects/housing_prices/find_prices_nonoverlap.py\u001b[0m(121)\u001b[0;36mtransform\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m    120 \u001b[1;33m        \u001b[1;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m--> 121 \u001b[1;33m        \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_required_fields\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    122 \u001b[1;33m        \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_to_nan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "find_prices_nonoverlap.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df.drop(labels=key, axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m/Users/derringi/Dropbox/projects/job_projects/housing_prices/find_prices_nonoverlap.py\u001b[0m(96)\u001b[0;36mtransform\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     95 \u001b[1;33m        \u001b[1;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 96 \u001b[1;33m        \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     97 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> df.keys()\n",
      "Index([u'address', u'zipcode', u'latitude', u'longitude', u'bedrooms',\n",
      "       u'bathrooms', u'rooms', u'squareFootage', u'lotSize', u'yearBuilt',\n",
      "       u'estimated_value'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "x_train = prepare_data_pipeline.fit_transform(X = df_train, y = y_train)\n",
    "\n",
    "print(\"Fitting model on training data\")\n",
    "model = fit_data_pipeline.fit(X = x_train, y = y_train)\n",
    "\n",
    "print(\"Evaluating model on training data\")\n",
    "y_pred = model.predict(x_train)\n",
    "print_metrics(y_train, y_pred)\n",
    "plt.plot((y_train), (y_pred),'.')\n",
    "y_max = (np.max((y_train, y_pred)))\n",
    "plt.plot((0,y_max), (0,y_max),color='black')\n",
    "plt.show()\n",
    "\n",
    "print(\"Evaluating model on testing data\")\n",
    "X_test = prepare_data_pipeline.transform(df_test)\n",
    "y_test_pred = model.predict(X_test)\n",
    "print_metrics(y_test, y_test_pred)\n",
    "plt.plot((y_test), (y_test_pred),'.', alpha=0.2)\n",
    "y_max = (np.max((y_test, y_test_pred)))\n",
    "plt.plot((0,y_max), (0,y_max),color='black')\n",
    "plt.xlim(0,1e6)\n",
    "plt.ylim(0,1e6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " ['address','latitude','longitude','zipcode','bedrooms',\n",
    "                   'bathrooms','rooms','squareFootage',\n",
    "                   'lotSize','yearBuilt', 'lastSaleAmount' \n",
    "                   'lastSaleDate','estimated_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[c,b] = np.histogram(y_pred-y, bins=np.linspace(-1e6,1e6,100))\n",
    "print(np.mean(y_pred-y))\n",
    "plt.plot(b[:-1],c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "sns.distplot(np.log(df['lastSaleAmount'].values+1))\n",
    " plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#: Work on using grid-searches\n",
    "params = {'forest__n_estimators':  (39,42)}\n",
    "# params = {'forest__n_estimators':  np.arange(3,31,3)}\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "# transformer = FunctionTransformer(np.log1p)\n",
    "# transformer.transform(y)\n",
    "grid = GridSearchCV(pipeline, params)\n",
    "grid.fit(X = X, y = y)\n",
    "\n",
    "#: Definining a specified cross-validation technique\n",
    "cv= StratifiedKFold(n_splits=2)\n",
    "\n",
    "# Alternatively, can say can say cv=3 to say a 3-repeat cross-validator\n",
    "grid_search = GridSearchCV(pipeline, params)#, cv=cv)\n",
    "#gsearch = GridSearchCV(pipeline, params)\n",
    "grid_search.fit(X = X, y = y)\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "best_pipeline.get_params()['forest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "best_pipeline = grid_search.best_estimator_\n",
    "best_pipeline.get_params()['forest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = X_test\n",
    "y=y_test\n",
    "y_pred = best_pipeline.predict(X)\n",
    "print(np.sqrt(metrics.mean_squared_error(y,y_pred)))\n",
    "print(metrics.mean_absolute_error(y,y_pred))\n",
    "print(metrics.r2_score(y,y_pred))\n",
    "print(abs_mean_relative_error(y,y_pred))\n",
    "plt.plot(y, y_pred,'.')\n",
    "y_max = np.max((y, y_pred))\n",
    "plt.plot((0,y_max), (0,y_max),color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "required_fields = ['address','latitude','longitude','zipcode','bedrooms',\n",
    "                   'bathrooms','rooms','squareFootage',\n",
    "                   'lotSize','yearBuilt',\n",
    "                   'lastSaleDate','estimated_value']\n",
    "for key in iter(df.keys()):\n",
    "    if key not in required_fields:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop(column=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop(labels='id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
